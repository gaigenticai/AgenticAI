# FluentD configuration for Agentic Platform Log Aggregation
# This configuration aggregates logs from all services and forwards to multiple destinations

# Input sources - collect logs from all services
<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

# HTTP input for log ingestion
<source>
  @type http
  port 8888
  bind 0.0.0.0
  body_size_limit 32m
  keepalive_timeout 10s
</source>

# Collect Docker container logs
<source>
  @type tail
  @id docker_containers
  path /var/lib/docker/containers/*/*-json.log
  pos_file /var/log/fluentd/docker.pos
  time_format %Y-%m-%dT%H:%M:%S.%NZ
  tag docker.*
  format json
  read_from_head true
</source>

# Collect system logs
<source>
  @type tail
  @id system_logs
  path /var/log/syslog, /var/log/messages
  pos_file /var/log/fluentd/syslog.pos
  tag system.*
  format syslog
  time_format %Y-%m-%d %H:%M:%S
</source>

# Filter - Add service identification
<filter docker.var.lib.docker.containers.*.*.log>
  @type record_transformer
  <record>
    service_name ${tag_parts[4]}
    container_id ${tag_parts[3]}
    source_type docker
  </record>
</filter>

# Filter - Parse JSON logs from containers
<filter docker.*>
  @type parser
  key_name log
  format json
  reserve_data true
</filter>

# Filter - Add timestamp and correlation ID
<filter *>
  @type record_transformer
  <record>
    timestamp ${time}
    correlation_id ${record["correlation_id"] || "unknown"}
    log_level ${record["level"] || record["log_level"] || "info"}
    service_version ${record["version"] || "unknown"}
  </record>
</filter>

# Filter - Add environment information
<filter *>
  @type record_transformer
  <record>
    environment production
    platform agentic-ai
    cluster local
  </record>
</filter>

# Output - Elasticsearch for log search
<match agentic.*>
  @type elasticsearch
  host elasticsearch_output
  port 9200
  logstash_format true
  logstash_prefix agentic-logs
  include_tag_key true
  tag_key @log_name
  flush_interval 10s
  buffer_type memory
  buffer_chunk_limit 1m
  buffer_queue_limit 10
  retry_limit 17
  retry_wait 1.0
  reconnect_on_error true
  reload_on_failure true
</match>

# Output - PostgreSQL for structured audit logs
<match audit.*>
  @type pgsql
  host postgresql_output
  port 5432
  database agentic_output
  username agentic_user
  password "#{ENV['POSTGRES_OUTPUT_PASSWORD'] || ''}"
  table audit_logs
  column_names timestamp,level,message,service_name,user_id,action,resource
  column_types timestamp,text,text,text,text,text,text
  <buffer>
    @type memory
    flush_interval 10s
  </buffer>
</match>

# Output - File backup
<match *>
  @type file
  path /fluentd/log/agentic
  time_slice_format %Y%m%d
  time_slice_wait 10m
  compress gzip
  <buffer time>
    timekey 1h
    timekey_wait 10m
  </buffer>
</match>

# Output - stdout for debugging (only in development)
<match debug.*>
  @type stdout
  <format>
    @type json
  </format>
</match>

# Error handling
<match **>
  @type copy
  <store>
    @type file
    path /fluentd/log/error
    time_slice_format %Y%m%d
    compress gzip
  </store>
  <store>
    @type stdout
  </store>
</match>
